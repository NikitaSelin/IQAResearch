{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lpips\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from DISTS_pytorch import DISTS\n",
    "import pyiqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikis\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nikis\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: c:\\Users\\nikis\\anaconda3\\Lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikis\\anaconda3\\Lib\\site-packages\\lpips\\lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n",
      "c:\\Users\\nikis\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\nikis\\anaconda3\\Lib\\site-packages\\DISTS_pytorch\\DISTS_pt.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(os.path.join(sys.prefix,'weights.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model NIMA from C:\\Users\\nikis\\.cache\\torch\\hub\\pyiqa\\NIMA_InceptionV2_ava-b0c77c00.pth\n"
     ]
    }
   ],
   "source": [
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "D = DISTS().to(device)\n",
    "nima = pyiqa.create_metric('nima', device=device)\n",
    "ahiq = pyiqa.create_metric('ahiq', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrgan_lpips_scores = {}\n",
    "esrgan_lpips_scores[\"image_name\"] = []\n",
    "esrgan_lpips_scores[\"MOS\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:13<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    esrgan_lpips_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"results_ESRGAN/{image_name[:-4]}_out.jpg\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = (img0 / 127.5) - 1\n",
    "    img1 = (img1 / 127.5) - 1\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0)\n",
    "    img1 = torch.tensor(img1)\n",
    "\n",
    "    d = loss_fn_alex(img0, img1)\n",
    "    esrgan_lpips_scores[\"MOS\"].append(float((10 * (1 - d))[0, 0, 0, 0]))\n",
    "    df = pd.DataFrame(esrgan_lpips_scores)\n",
    "    df.to_csv(\"ESRGAN_LPIPS_scores.csv\")\n",
    "    count += 1\n",
    "    if count == 3746:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_esrgan_lpips_scores = {}\n",
    "real_esrgan_lpips_scores[\"image_name\"] = []\n",
    "real_esrgan_lpips_scores[\"scores\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    real_esrgan_lpips_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"results_Real-ESRGAN/{image_name[:-4]}_out.jpg\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = (img0 / 127.5) - 1\n",
    "    img1 = (img1 / 127.5) - 1\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0)\n",
    "    img1 = torch.tensor(img1)\n",
    "\n",
    "    d = loss_fn_alex(img0, img1)\n",
    "    real_esrgan_lpips_scores[\"scores\"].append(float((10 * (1 - d))[0, 0, 0, 0]))\n",
    "    df = pd.DataFrame(real_esrgan_lpips_scores)\n",
    "    df.to_csv(\"Real-ESRGAN_LPIPS_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicubic_lpips_scores = {}\n",
    "bicubic_lpips_scores[\"image_name\"] = []\n",
    "bicubic_lpips_scores[\"scores\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:13<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    bicubic_lpips_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"bicubic/{image_name}\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = (img0 / 127.5) - 1\n",
    "    img1 = (img1 / 127.5) - 1\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0)\n",
    "    img1 = torch.tensor(img1)\n",
    "\n",
    "    d = loss_fn_alex(img0, img1)\n",
    "    bicubic_lpips_scores[\"scores\"].append(float((10 * (1 - d))[0, 0, 0, 0]))\n",
    "    df = pd.DataFrame(bicubic_lpips_scores)\n",
    "    df.to_csv(\"bicubic_LPIPS_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrgan_dists_scores = {}\n",
    "esrgan_dists_scores[\"image_name\"] = []\n",
    "esrgan_dists_scores[\"MOS\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    esrgan_dists_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"results_ESRGAN/{image_name[:-4]}_out.jpg\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = img0 / 255\n",
    "    img1 = img1 / 255\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0).to(device)\n",
    "    img1 = torch.tensor(img1).to(device)\n",
    "\n",
    "    d = D(img0, img1)\n",
    "    del img0\n",
    "    del img1\n",
    "    esrgan_dists_scores[\"MOS\"].append(float(10 * (1 - d)))\n",
    "    df = pd.DataFrame(esrgan_dists_scores)\n",
    "    df.to_csv(\"ESRGAN_DISTS_scores.csv\")\n",
    "    count += 1\n",
    "    if count == 3746:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_esrgan_dists_scores = {}\n",
    "real_esrgan_dists_scores[\"image_name\"] = []\n",
    "real_esrgan_dists_scores[\"score\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    real_esrgan_dists_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"results_Real-ESRGAN/{image_name[:-4]}_out.jpg\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = img0 / 255\n",
    "    img1 = img1 / 255\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0).to(device)\n",
    "    img1 = torch.tensor(img1).to(device)\n",
    "\n",
    "    d = D(img0, img1)\n",
    "    del img0\n",
    "    del img1\n",
    "    real_esrgan_dists_scores[\"score\"].append(float(10 * (1 - d)))\n",
    "    df = pd.DataFrame(real_esrgan_dists_scores)\n",
    "    df.to_csv(\"Real-ESRGAN_DISTS_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicubic_dists_scores = {}\n",
    "bicubic_dists_scores[\"image_name\"] = []\n",
    "bicubic_dists_scores[\"scores\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    bicubic_dists_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"bicubic/{image_name}\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = img0 / 255\n",
    "    img1 = img1 / 255\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0).to(device)\n",
    "    img1 = torch.tensor(img1).to(device)\n",
    "\n",
    "    d = D(img0, img1)\n",
    "    del img0\n",
    "    del img1\n",
    "    bicubic_dists_scores[\"scores\"].append(float(10 * (1 - d)))\n",
    "    df = pd.DataFrame(bicubic_dists_scores)\n",
    "    df.to_csv(\"bicubic_DISTS_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrgan_nima_scores = {}\n",
    "esrgan_nima_scores[\"image_name\"] = []\n",
    "esrgan_nima_scores[\"MOS\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  6.72it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    esrgan_nima_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"results_ESRGAN/{image_name[:-4]}_out.jpg\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = img0 / 255\n",
    "    img1 = img1 / 255\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0)\n",
    "    img1 = torch.tensor(img1)\n",
    "\n",
    "    d = nima(img0, img1)\n",
    "    esrgan_nima_scores[\"MOS\"].append(float(d))\n",
    "    df = pd.DataFrame(esrgan_nima_scores)\n",
    "    df.to_csv(\"ESRGAN_NIMA_scores.csv\")\n",
    "    count += 1\n",
    "    if count == 3746:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_esrgan_nima_scores = {}\n",
    "real_esrgan_nima_scores[\"image_name\"] = []\n",
    "real_esrgan_nima_scores[\"score\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  7.05it/s]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    real_esrgan_nima_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"results_Real-ESRGAN/{image_name[:-4]}_out.jpg\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = img0 / 255\n",
    "    img1 = img1 / 255\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0)\n",
    "    img1 = torch.tensor(img1)\n",
    "\n",
    "    d = nima(img0, img1)\n",
    "    real_esrgan_nima_scores[\"score\"].append(float(d))\n",
    "    df = pd.DataFrame(real_esrgan_nima_scores)\n",
    "    df.to_csv(\"Real-ESRGAN_NIMA_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bicubic_nima_scores = {}\n",
    "bicubic_nima_scores[\"image_name\"] = []\n",
    "bicubic_nima_scores[\"score\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  6.07it/s]\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"original_images\")\n",
    "for image_name in tqdm(images):\n",
    "    bicubic_nima_scores[\"image_name\"].append(image_name)\n",
    "    img0 = cv2.imread(f\"original_images/{image_name}\")\n",
    "    img1 = cv2.imread(f\"bicubic/{image_name}\")\n",
    "\n",
    "    img0 = img0.reshape(1, 3, 768, 1024)\n",
    "    img1 = img1.reshape(1, 3, 768, 1024)\n",
    "\n",
    "    img0 = img0 / 255\n",
    "    img1 = img1 / 255\n",
    "\n",
    "    img0 = img0.astype(np.float32)\n",
    "    img1 = img1.astype(np.float32)\n",
    "\n",
    "    img0 = torch.tensor(img0)\n",
    "    img1 = torch.tensor(img1)\n",
    "\n",
    "    d = nima(img0, img1)\n",
    "    bicubic_nima_scores[\"score\"].append(float(d))\n",
    "    df = pd.DataFrame(bicubic_nima_scores)\n",
    "    df.to_csv(\"bicubic_NIMA_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrgan_ahiq_scores = {}\n",
    "esrgan_ahiq_scores[\"image_name\"] = []\n",
    "esrgan_ahiq_scores[\"MOS\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026\n"
     ]
    }
   ],
   "source": [
    "df_ESRGAN_lpips = pd.read_csv(\"ESRGAN_LPIPS_scores.csv\")\n",
    "df_Real_ESRGAN_lpips = pd.read_csv(\"Real-ESRGAN_LPIPS_scores.csv\")\n",
    "df_bicubic_lpips = pd.read_csv(\"bicubic_LPIPS_scores.csv\")\n",
    "df_ESRGAN_dists = pd.read_csv(\"ESRGAN_DISTS_scores.csv\")\n",
    "df_Real_ESRGAN_dists = pd.read_csv(\"Real-ESRGAN_DISTS_scores.csv\")\n",
    "df_bicubic_dists = pd.read_csv(\"bicubic_DISTS_scores.csv\")\n",
    "df_ESRGAN_nima = pd.read_csv(\"ESRGAN_NIMA_scores.csv\")\n",
    "df_Real_ESRGAN_nima = pd.read_csv(\"Real-ESRGAN_NIMA_scores.csv\")\n",
    "df_bicubic_nima = pd.read_csv(\"bicubic_NIMA_scores.csv\")\n",
    "\n",
    "gt_scores = pd.read_csv(\"gt_scores.csv\")\n",
    "gt_scores_esrgan_mean = gt_scores[[\"score_esrgan_n\", \"PG_score_esrgan\"]].mean(axis=1).values\n",
    "gt_scores_real_esrgan_mean = gt_scores[[\"score_real_esrgan_n\", \"PG_score_real_srgan\"]].mean(axis=1).values\n",
    "gt_scores_bicubic_mean = gt_scores[[\"score_bicubic_n\", \"PG_score_bicubic\"]].mean(axis=1).values\n",
    "\n",
    "correlations_esrgan = {}\n",
    "correlations_real_esrgan = {}\n",
    "correlations_bicubic = {}\n",
    "\n",
    "pearson_esrgan_lpips = round(pearsonr(gt_scores_esrgan_mean, df_ESRGAN_lpips[\"MOS\"].values)[0], 3)\n",
    "pearson_real_esrgan_lpips = round(pearsonr(gt_scores_real_esrgan_mean, df_Real_ESRGAN_lpips[\"scores\"].values)[0], 3)\n",
    "pearson_bicubic_lpips = round(pearsonr(gt_scores_bicubic_mean, df_bicubic_lpips[\"scores\"].values)[0], 3)\n",
    "pearson_esrgan_dists = round(pearsonr(gt_scores_esrgan_mean, df_ESRGAN_dists[\"MOS\"].values)[0], 3)\n",
    "pearson_real_esrgan_dists = round(pearsonr(gt_scores_real_esrgan_mean, df_Real_ESRGAN_dists[\"score\"].values)[0], 3)\n",
    "pearson_bicubic_dists = round(pearsonr(gt_scores_bicubic_mean, df_bicubic_dists[\"scores\"].values)[0], 3)\n",
    "pearson_esrgan_nima = round(pearsonr(gt_scores_esrgan_mean, df_ESRGAN_nima[\"MOS\"].values)[0], 3)\n",
    "pearson_real_esrgan_nima = round(pearsonr(gt_scores_real_esrgan_mean, df_Real_ESRGAN_nima[\"score\"].values)[0], 3)\n",
    "pearson_bicubic_nima = round(pearsonr(gt_scores_bicubic_mean, df_bicubic_nima[\"score\"].values)[0], 3)\n",
    "\n",
    "spearman_esrgan_lpips = round(spearmanr(gt_scores_esrgan_mean, df_ESRGAN_lpips[\"MOS\"].values)[0], 3)\n",
    "spearman_real_esrgan_lpips = round(spearmanr(gt_scores_real_esrgan_mean, df_Real_ESRGAN_lpips[\"scores\"].values)[0], 3)\n",
    "spearman_bicubic_lpips = round(spearmanr(gt_scores_bicubic_mean, df_bicubic_lpips[\"scores\"].values)[0], 3)\n",
    "spearman_esrgan_dists = round(spearmanr(gt_scores_esrgan_mean, df_ESRGAN_dists[\"MOS\"].values)[0], 3)\n",
    "spearman_real_esrgan_dists = round(spearmanr(gt_scores_real_esrgan_mean, df_Real_ESRGAN_dists[\"score\"].values)[0], 3)\n",
    "spearman_bicubic_dists = round(spearmanr(gt_scores_bicubic_mean, df_bicubic_dists[\"scores\"].values)[0], 3)\n",
    "spearman_esrgan_nima = round(spearmanr(gt_scores_esrgan_mean, df_ESRGAN_nima[\"MOS\"].values)[0], 3)\n",
    "spearman_real_esrgan_nima = round(spearmanr(gt_scores_real_esrgan_mean, df_Real_ESRGAN_nima[\"score\"].values)[0], 3)\n",
    "spearman_bicubic_nima = round(spearmanr(gt_scores_bicubic_mean, df_bicubic_nima[\"score\"].values)[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {\n",
    "    \"LPIPS\": [\n",
    "        f\"{pearson_esrgan_lpips}/{spearman_esrgan_lpips}\",\n",
    "        f\"{pearson_real_esrgan_lpips}/{spearman_real_esrgan_lpips}\",\n",
    "        f\"{pearson_bicubic_lpips}/{spearman_bicubic_lpips}\"\n",
    "    ],\n",
    "    \"DISTS\": [\n",
    "        f\"{pearson_esrgan_dists}/{spearman_esrgan_dists}\",\n",
    "        f\"{pearson_real_esrgan_dists}/{spearman_real_esrgan_dists}\",\n",
    "        f\"{pearson_bicubic_dists}/{spearman_bicubic_dists}\"\n",
    "    ],\n",
    "    \"NIMA\": [\n",
    "        f\"{pearson_esrgan_nima}/{spearman_esrgan_nima}\",\n",
    "        f\"{pearson_real_esrgan_nima}/{spearman_real_esrgan_nima}\",\n",
    "        f\"{pearson_bicubic_nima}/{spearman_bicubic_nima}\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LPIPS': ['0.026/0.01', '0.123/0.088', '0.501/0.6'],\n",
       " 'DISTS': ['0.224/0.291', '0.378/0.37', '0.59/0.655'],\n",
       " 'NIMA': ['0.001/0.106', '-0.12/-0.01', '-0.477/-0.482']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LPIPS</th>\n",
       "      <th>DISTS</th>\n",
       "      <th>NIMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ESRGAN</th>\n",
       "      <td>0.026/0.01</td>\n",
       "      <td>0.224/0.291</td>\n",
       "      <td>0.001/0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real-ESRGAN</th>\n",
       "      <td>0.123/0.088</td>\n",
       "      <td>0.378/0.37</td>\n",
       "      <td>-0.12/-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicubic</th>\n",
       "      <td>0.501/0.6</td>\n",
       "      <td>0.59/0.655</td>\n",
       "      <td>-0.477/-0.482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   LPIPS        DISTS           NIMA\n",
       "ESRGAN        0.026/0.01  0.224/0.291    0.001/0.106\n",
       "Real-ESRGAN  0.123/0.088   0.378/0.37    -0.12/-0.01\n",
       "bicubic        0.501/0.6   0.59/0.655  -0.477/-0.482"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations_df = pd.DataFrame(correlations, index=[\"ESRGAN\", \"Real-ESRGAN\", \"bicubic\"])\n",
    "correlations_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
